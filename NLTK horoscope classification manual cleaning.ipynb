{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook Uses:\n",
    "\n",
    "Sentences tokenization/ Words tokenization for X\n",
    "Label encoding/ to categorical function of keras for y\n",
    "and softmax in final layer\n",
    "##### not giving desired results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ebryx/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ebryx/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ebryx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "# from xml.dom import minidom\n",
    "from lxml import etree\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to read All csv ::  0.03780341148376465  seconds \n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "path='./dataset/blogs_train/'\n",
    "all_files = glob.glob(path + \"/*.xml\")\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "  # print(\"file name \", filename)\n",
    "  li.append(filename)\n",
    "    \n",
    "\n",
    "t2=time.time()\n",
    "print(\"time taken to read All csv :: \", t2-t1, \" seconds \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_file_names(li):\n",
    "  # names_list=[]\n",
    "  # for i in range(len(li)):\n",
    "  name_list=li.split('/')[-1]\n",
    "  return name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_attributes_from_name(name):\n",
    "  # data_object=[]\n",
    "  # for data in range(len(names_list)):\n",
    "  #   dummy_var=names_list[data].split('.')\n",
    "  #   dummy_object={'id':dummy_var[0], 'gender':dummy_var[1],\n",
    "  #                 'age':dummy_var[2], 'category':dummy_var[3],\n",
    "  #                 'horoscope':dummy_var[4]\n",
    "  #                 }\n",
    "  #   data_object.append(dummy_object)\n",
    "  dummy_var=name.split('.')\n",
    "  data_object={'id':dummy_var[0], 'gender':dummy_var[1],\n",
    "                  'age':dummy_var[2], 'category':dummy_var[3],\n",
    "                  'horoscope':dummy_var[4]\n",
    "                }\n",
    "  \n",
    "  return data_object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = etree.XMLParser(encoding='ISO-8859-1', recover = True, huge_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml(li):\n",
    "  all_objects=[]\n",
    "  for i in range(len(li)):\n",
    "    # print(\"i will run \", i+1,\" times\")\n",
    "    name_of_file=clean_file_names(li[i])\n",
    "    # print(name_of_file)\n",
    "    data_object=get_attributes_from_name(name_of_file)\n",
    "    # print(data_object)\n",
    "\n",
    "    post_text='  '\n",
    "    tree = etree.parse(li[i], parser=parser)\n",
    "    root = tree.getroot()\n",
    "    for element in root.iter():\n",
    "        if element.tag == 'post':\n",
    "            element_text = element.text\n",
    "            post_text = post_text + element_text\n",
    "    mystring = post_text.replace('\\n', '').replace('\\r', '').replace('\\t', '')\n",
    "    mystring = mystring.replace('   ', '').replace('\\\\','')\n",
    "   \n",
    "\n",
    "#     mystring=clean_my_string(mystring)\n",
    "   \n",
    "    # print(mystring)\n",
    "    # name_of_file=clean_file_names(li[i])\n",
    "    # data_object=get_attributes_from_name(name_of_file)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    data_object['posts']=mystring   \n",
    "    all_objects.append(data_object)\n",
    "\n",
    "  return all_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=time.time()\n",
    "data=read_xml(li[0:])\n",
    "t2=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to read ::  0.11188389539718628\n"
     ]
    }
   ],
   "source": [
    "print(\"time taken to read :: \", (t2-t1)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    post_of_single_person=data[i]['posts']\n",
    "    \n",
    "    sentences=sent_tokenize(post_of_single_person)\n",
    "    \n",
    "    for j in range(len(sentences)):\n",
    "        words=word_tokenize(sentences[j])[:-1]\n",
    "        \n",
    "        sentences[j]=words\n",
    "        \n",
    "    data[i]['posts']=sentences\n",
    "    \n",
    "#     sentence=word_tokenize(sent_tokenize(post_of_single_person)[3])[:-1]\n",
    "#     sentences+=sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.726801433563232"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(time.time()-t2)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>category</th>\n",
       "      <th>horoscope</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960525</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Libra</td>\n",
       "      <td>[[i, know, ,, i, need, to, be, getting, sleep,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3949642</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>[[love, studying, ?, ca, n't, get, enough, of,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>688097</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Education</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>[[Im, currently, updating, my, site], [And, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>963380</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>[[So, I, was, a, witness, to, a, pretty, nasty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4055698</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>[[ok, so, we, skipped, multimedia, computer, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  gender age   category    horoscope  \\\n",
       "0  1960525    male  15    Student        Libra   \n",
       "1  3949642    male  25     indUnk          Leo   \n",
       "2   688097    male  17  Education       Cancer   \n",
       "3   963380    male  24    Student       Cancer   \n",
       "4  4055698  female  17     indUnk  Sagittarius   \n",
       "\n",
       "                                               posts  \n",
       "0  [[i, know, ,, i, need, to, be, getting, sleep,...  \n",
       "1  [[love, studying, ?, ca, n't, get, enough, of,...  \n",
       "2  [[Im, currently, updating, my, site], [And, al...  \n",
       "3  [[So, I, was, a, witness, to, a, pretty, nasty...  \n",
       "4  [[ok, so, we, skipped, multimedia, computer, l...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>category</th>\n",
       "      <th>horoscope</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14595</th>\n",
       "      <td>3122872</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Libra</td>\n",
       "      <td>[[ok, we, got, webspace, off, abp, for, bgs, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14596</th>\n",
       "      <td>3322392</td>\n",
       "      <td>female</td>\n",
       "      <td>15</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>[[dearest, diary, ,, i, do, not, know, wad, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14597</th>\n",
       "      <td>4008208</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>[[Good, friends, are, the, greatest, treasures...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14598</th>\n",
       "      <td>1599685</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>[[WE, BRING, THIS, SPECIAL, ANNOUCEMENT, TO, Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14599</th>\n",
       "      <td>1608709</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>Aries</td>\n",
       "      <td>[[Football, Alex, 'Knight, of, the, Realm, ', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  gender age    category  horoscope  \\\n",
       "14595  3122872    male  15     Student      Libra   \n",
       "14596  3322392  female  15      indUnk     Pisces   \n",
       "14597  4008208  female  16      indUnk     Pisces   \n",
       "14598  1599685    male  23     Student  Capricorn   \n",
       "14599  1608709    male  25  Accounting      Aries   \n",
       "\n",
       "                                                   posts  \n",
       "14595  [[ok, we, got, webspace, off, abp, for, bgs, b...  \n",
       "14596  [[dearest, diary, ,, i, do, not, know, wad, to...  \n",
       "14597  [[Good, friends, are, the, greatest, treasures...  \n",
       "14598  [[WE, BRING, THIS, SPECIAL, ANNOUCEMENT, TO, Y...  \n",
       "14599  [[Football, Alex, 'Knight, of, the, Realm, ', ...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['posts'].values\n",
    "y=df['horoscope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(trainX)):\n",
    "    sentences=trainX[i]\n",
    "    words=''\n",
    "    for j in range(len(sentences)):\n",
    "        sentence=sentences[j]\n",
    "        for k in range(len(sentence)):\n",
    "            words+=' '+sentence[k]\n",
    "    trainX[i]=words   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(testX)):\n",
    "    sentences=testX[i]\n",
    "    words=''\n",
    "    for j in range(len(sentences)):\n",
    "        sentence=sentences[j]\n",
    "        for k in range(len(sentence)):\n",
    "            words+=' '+sentence[k]\n",
    "    testX[i]=words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(trainX)\n",
    "X_train = vectorizer.transform(trainX)\n",
    "X_test  = vectorizer.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Aquarius', 'Aries', 'Cancer', 'Capricorn', 'Gemini', 'Leo',\n",
       "       'Libra', 'Pisces', 'Sagittarius', 'Scorpio', 'Taurus', 'Virgo'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(trainY)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>category</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horoscope</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aquarius</th>\n",
       "      <td>3386199</td>\n",
       "      <td>female</td>\n",
       "      <td>36</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>[[cathartic, ramblings, -, that, 's, how, my, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aries</th>\n",
       "      <td>3998125</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>[[Today, was, a, good, day, for, me], [A, litt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cancer</th>\n",
       "      <td>688097</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Education</td>\n",
       "      <td>[[Im, currently, updating, my, site], [And, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Capricorn</th>\n",
       "      <td>2667280</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>Communications-Media</td>\n",
       "      <td>[[is, it, just, me, or, are, most, famous, peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gemini</th>\n",
       "      <td>4080749</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Arts</td>\n",
       "      <td>[[ok, i, was, @, me, aunt, 's, house, ..., .an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leo</th>\n",
       "      <td>3949642</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>[[love, studying, ?, ca, n't, get, enough, of,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Libra</th>\n",
       "      <td>1960525</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>[[i, know, ,, i, need, to, be, getting, sleep,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pisces</th>\n",
       "      <td>1822234</td>\n",
       "      <td>female</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>[[what, an, end, to, my, week], [It, 's, been,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sagittarius</th>\n",
       "      <td>4055698</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>[[ok, so, we, skipped, multimedia, computer, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scorpio</th>\n",
       "      <td>3991185</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>[[iN, 1885, ..., OuR, foUnDer, gAn, eNG, sEnG,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taurus</th>\n",
       "      <td>2747575</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>[[I, watched, a, whole, 2, movies, today], [Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virgo</th>\n",
       "      <td>1178991</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Technology</td>\n",
       "      <td>[[urlLink, Here, is, a, really, great, resourc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  gender age              category  \\\n",
       "horoscope                                                \n",
       "Aquarius     3386199  female  36                indUnk   \n",
       "Aries        3998125    male  23                indUnk   \n",
       "Cancer        688097    male  17             Education   \n",
       "Capricorn    2667280  female  24  Communications-Media   \n",
       "Gemini       4080749    male  15                  Arts   \n",
       "Leo          3949642    male  25                indUnk   \n",
       "Libra        1960525    male  15               Student   \n",
       "Pisces       1822234  female  33                indUnk   \n",
       "Sagittarius  4055698  female  17                indUnk   \n",
       "Scorpio      3991185    male  14                indUnk   \n",
       "Taurus       2747575    male  17               Student   \n",
       "Virgo        1178991    male  24            Technology   \n",
       "\n",
       "                                                         posts  \n",
       "horoscope                                                       \n",
       "Aquarius     [[cathartic, ramblings, -, that, 's, how, my, ...  \n",
       "Aries        [[Today, was, a, good, day, for, me], [A, litt...  \n",
       "Cancer       [[Im, currently, updating, my, site], [And, al...  \n",
       "Capricorn    [[is, it, just, me, or, are, most, famous, peo...  \n",
       "Gemini       [[ok, i, was, @, me, aunt, 's, house, ..., .an...  \n",
       "Leo          [[love, studying, ?, ca, n't, get, enough, of,...  \n",
       "Libra        [[i, know, ,, i, need, to, be, getting, sleep,...  \n",
       "Pisces       [[what, an, end, to, my, week], [It, 's, been,...  \n",
       "Sagittarius  [[ok, so, we, skipped, multimedia, computer, l...  \n",
       "Scorpio      [[iN, 1885, ..., OuR, foUnDer, gAn, eNG, sEnG,...  \n",
       "Taurus       [[I, watched, a, whole, 2, movies, today], [Th...  \n",
       "Virgo        [[urlLink, Here, is, a, really, great, resourc...  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('horoscope').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=le.transform(trainY)\n",
    "y_test=le.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_train_y = np_utils.to_categorical(y_train)\n",
    "dummy_test_y = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(20, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(10,  activation='tanh'))\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(1024, activation='relu'))\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    "# model.add(Activation('softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11680, 696228)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 20)                13924580  \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 12)                132       \n",
      "=================================================================\n",
      "Total params: 13,924,922\n",
      "Trainable params: 13,924,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11680 samples, validate on 2920 samples\n",
      "Epoch 1/2\n",
      "11680/11680 [==============================] - 267s 23ms/step - loss: 0.2964 - acc: 0.9163 - val_loss: 0.2867 - val_acc: 0.9167\n",
      "Epoch 2/2\n",
      "11680/11680 [==============================] - 280s 24ms/step - loss: 0.2868 - acc: 0.9167 - val_loss: 0.2868 - val_acc: 0.9167\n"
     ]
    }
   ],
   "source": [
    "classifier_nn = model.fit(X_train,dummy_train_y,\n",
    "                    epochs=2,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, dummy_test_y),\n",
    "                    batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07839546, 0.08526174, 0.08882953, 0.07589879, 0.0808452 ,\n",
       "        0.08593997, 0.08922673, 0.08013301, 0.07589357, 0.0854533 ,\n",
       "        0.08447116, 0.08965152]], dtype=float32)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07839546, 0.08526174, 0.08882953, 0.07589879, 0.0808452 ,\n",
       "        0.08593997, 0.08922673, 0.08013301, 0.07589357, 0.0854533 ,\n",
       "        0.08447116, 0.08965152]], dtype=float32)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[88])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_test_y[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sentences, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "del classifier_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train[:1000],y_train[:1000])\n",
    "score = classifier.score(X_test[:500], y_test[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.predict(X_test[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
