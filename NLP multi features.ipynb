{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ebryx/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ebryx/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ebryx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "# from xml.dom import minidom\n",
    "from lxml import etree\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to read All csv ::  0.0993509292602539  seconds \n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "path='./dataset/blogs_train/'\n",
    "all_files = glob.glob(path + \"/*.xml\")\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "  # print(\"file name \", filename)\n",
    "  li.append(filename)\n",
    "    \n",
    "\n",
    "t2=time.time()\n",
    "print(\"time taken to read All csv :: \", t2-t1, \" seconds \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_file_names(li):\n",
    "  # names_list=[]\n",
    "  # for i in range(len(li)):\n",
    "  name_list=li.split('/')[-1]\n",
    "  return name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_attributes_from_name(name):\n",
    "  # data_object=[]\n",
    "  # for data in range(len(names_list)):\n",
    "  #   dummy_var=names_list[data].split('.')\n",
    "  #   dummy_object={'id':dummy_var[0], 'gender':dummy_var[1],\n",
    "  #                 'age':dummy_var[2], 'category':dummy_var[3],\n",
    "  #                 'horoscope':dummy_var[4]\n",
    "  #                 }\n",
    "  #   data_object.append(dummy_object)\n",
    "  dummy_var=name.split('.')\n",
    "  data_object={'id':dummy_var[0], 'gender':dummy_var[1],\n",
    "                  'age':dummy_var[2], 'category':dummy_var[3],\n",
    "                  'horoscope':dummy_var[4]\n",
    "                }\n",
    "  \n",
    "  return data_object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = etree.XMLParser(encoding='ISO-8859-1', recover = True, huge_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml(li):\n",
    "    \n",
    "    \n",
    "    all_objects=[]\n",
    "    for i in range(len(li)):\n",
    "    # print(\"i will run \", i+1,\" times\")\n",
    "        name_of_file=clean_file_names(li[i])\n",
    "    # print(name_of_file)\n",
    "        data_object=get_attributes_from_name(name_of_file)\n",
    "    # print(data_object)\n",
    "\n",
    "        post_text='  '\n",
    "        tree = etree.parse(li[i], parser=parser)\n",
    "        root = tree.getroot()\n",
    "        for element in root.iter():\n",
    "            if element.tag == 'post':\n",
    "                element_text = element.text\n",
    "                post_text = post_text + element_text\n",
    "        mystring = post_text.replace('\\n', '').replace('\\r', '').replace('\\t', '')\n",
    "        mystring = mystring.replace('   ', '').replace('\\\\','')\n",
    "   \n",
    "\n",
    "\n",
    "   \n",
    "    # print(mystring)\n",
    "    # name_of_file=clean_file_names(li[i])\n",
    "    # data_object=get_attributes_from_name(name_of_file)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        data_object['posts']=mystring   \n",
    "        all_objects.append(data_object)\n",
    "\n",
    "    return all_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=time.time()\n",
    "data=read_xml(li[0:100])\n",
    "t2=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "def remove_stop_words(posts):\n",
    "    filtered_post=[]\n",
    "    \n",
    "    word_tokens = word_tokenize(posts) \n",
    "    filtered_sentence = []   \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "\n",
    "    filtered_post.append(filtered_sentence)\n",
    "    return filtered_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "def fun_remove_stop_words(posts):\n",
    "    filtered=''\n",
    "    for x in posts.split(' '):\n",
    "        if x not in stop_words:\n",
    "            filtered+=' '+x\n",
    "    return filtered    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data[i]['cleaned_stop_words']=fun_remove_stop_words(data[i]['posts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dashes(data):\n",
    "    for i in range(len(data)):\n",
    "        data[i]['cleaned_stop_words']=data[i]['cleaned_stop_words'].replace('--', ' ')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dashes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['age','cleaned_stop_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_variable_1 = pd.get_dummies(df[\"category\"])\n",
    "X=pd.concat([X,dummy_variable_1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dummy_variable_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X['cleaned_stop_words'])\n",
    "posts = vectorizer.transform(X['cleaned_stop_words'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x35680 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 137673 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_posts = np.array([row.toarray() for row in posts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_posts.shape=(100,35680)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f11af7c3289b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mposts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "del df,posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_posts=pd.DataFrame(transformed_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.concat([X,transformed_posts],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "del transformed_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.drop(['cleaned_stop_words'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Arts</th>\n",
       "      <th>Banking</th>\n",
       "      <th>BusinessServices</th>\n",
       "      <th>Communications-Media</th>\n",
       "      <th>Education</th>\n",
       "      <th>Engineering</th>\n",
       "      <th>Government</th>\n",
       "      <th>HumanResources</th>\n",
       "      <th>...</th>\n",
       "      <th>35670</th>\n",
       "      <th>35671</th>\n",
       "      <th>35672</th>\n",
       "      <th>35673</th>\n",
       "      <th>35674</th>\n",
       "      <th>35675</th>\n",
       "      <th>35676</th>\n",
       "      <th>35677</th>\n",
       "      <th>35678</th>\n",
       "      <th>35679</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 35700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  Advertising  Arts  Banking  BusinessServices  Communications-Media  \\\n",
       "0   15            0     0        0                 0                     0   \n",
       "1   25            0     0        0                 0                     0   \n",
       "2   17            0     0        0                 0                     0   \n",
       "3   24            0     0        0                 0                     0   \n",
       "4   17            0     0        0                 0                     0   \n",
       "..  ..          ...   ...      ...               ...                   ...   \n",
       "95  25            0     0        0                 0                     0   \n",
       "96  23            0     0        0                 1                     0   \n",
       "97  16            0     0        0                 0                     0   \n",
       "98  24            0     0        0                 0                     0   \n",
       "99  23            0     0        0                 0                     0   \n",
       "\n",
       "    Education  Engineering  Government  HumanResources  ...  35670  35671  \\\n",
       "0           0            0           0               0  ...      0      0   \n",
       "1           0            0           0               0  ...      0      0   \n",
       "2           1            0           0               0  ...      0      0   \n",
       "3           0            0           0               0  ...      0      0   \n",
       "4           0            0           0               0  ...      0      0   \n",
       "..        ...          ...         ...             ...  ...    ...    ...   \n",
       "95          0            0           0               0  ...      0      0   \n",
       "96          0            0           0               0  ...      0      0   \n",
       "97          0            0           0               0  ...      0      0   \n",
       "98          0            0           0               0  ...      0      0   \n",
       "99          0            0           0               0  ...      0      0   \n",
       "\n",
       "    35672  35673  35674  35675  35676  35677  35678  35679  \n",
       "0       0      0      0      0      0      0      0      0  \n",
       "1       0      0      0      0      0      0      0      0  \n",
       "2       0      0      0      0      0      0      0      0  \n",
       "3       0      0      0      0      0      0      0      0  \n",
       "4       0      0      0      0      0      0      0      0  \n",
       "..    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "95      0      0      0      0      0      0      0      0  \n",
       "96      0      0      0      0      0      0      0      0  \n",
       "97      0      0      0      0      0      0      0      0  \n",
       "98      0      0      0      0      0      0      0      0  \n",
       "99      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[100 rows x 35700 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['age']=X['age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time :::  0.001110076904296875  seconds to find z score\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "\n",
    "X['age'] = stats.zscore(X['age'])\n",
    "    \n",
    "t2=time.time()\n",
    "print(\"time ::: \", t2-t1 , \" seconds to find z score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Arts</th>\n",
       "      <th>Banking</th>\n",
       "      <th>BusinessServices</th>\n",
       "      <th>Communications-Media</th>\n",
       "      <th>Education</th>\n",
       "      <th>Engineering</th>\n",
       "      <th>Government</th>\n",
       "      <th>HumanResources</th>\n",
       "      <th>...</th>\n",
       "      <th>35670</th>\n",
       "      <th>35671</th>\n",
       "      <th>35672</th>\n",
       "      <th>35673</th>\n",
       "      <th>35674</th>\n",
       "      <th>35675</th>\n",
       "      <th>35676</th>\n",
       "      <th>35677</th>\n",
       "      <th>35678</th>\n",
       "      <th>35679</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.006980</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.216568</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.762271</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.094213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.762271</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  Advertising  Arts  Banking  BusinessServices  \\\n",
       "0 -1.006980            0     0        0                 0   \n",
       "1  0.216568            0     0        0                 0   \n",
       "2 -0.762271            0     0        0                 0   \n",
       "3  0.094213            0     0        0                 0   \n",
       "4 -0.762271            0     0        0                 0   \n",
       "\n",
       "   Communications-Media  Education  Engineering  Government  HumanResources  \\\n",
       "0                     0          0            0           0               0   \n",
       "1                     0          0            0           0               0   \n",
       "2                     0          1            0           0               0   \n",
       "3                     0          0            0           0               0   \n",
       "4                     0          0            0           0               0   \n",
       "\n",
       "   ...  35670  35671  35672  35673  35674  35675  35676  35677  35678  35679  \n",
       "0  ...      0      0      0      0      0      0      0      0      0      0  \n",
       "1  ...      0      0      0      0      0      0      0      0      0      0  \n",
       "2  ...      0      0      0      0      0      0      0      0      0      0  \n",
       "3  ...      0      0      0      0      0      0      0      0      0      0  \n",
       "4  ...      0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 35700 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>category</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>i know, i need to be getting sleep; i know, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>love studying?can't get enough of those fat b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>Education</td>\n",
       "      <td>Im currently updating my site. And almost doin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>Student</td>\n",
       "      <td>So I was a witness to a pretty nasty accident ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>ok so we skipped multimedia computer lecture...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age   category                                              posts\n",
       "0  15    Student   i know, i need to be getting sleep; i know, i...\n",
       "1  25     indUnk   love studying?can't get enough of those fat b...\n",
       "2  17  Education  Im currently updating my site. And almost doin...\n",
       "3  24    Student  So I was a witness to a pretty nasty accident ...\n",
       "4  17     indUnk    ok so we skipped multimedia computer lecture..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['cleaned_stop_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 int64\n",
       "Advertising         uint8\n",
       "Arts                uint8\n",
       "Banking             uint8\n",
       "BusinessServices    uint8\n",
       "                    ...  \n",
       "35675               int64\n",
       "35676               int64\n",
       "35677               int64\n",
       "35678               int64\n",
       "35679               int64\n",
       "Length: 35700, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_variable_1 = pd.get_dummies(df[\"category\"])\n",
    "df=pd.concat([df,dummy_variable_1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=pd.concat([df['age'],df['posts']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for x in df.columns:\n",
    "    i+=1\n",
    "    if i>7:\n",
    "        df_2=pd.concat([df_2,df[x]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=df_2.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_2['posts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X, X2], join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=pd.concat([df_2['posts'],df_2[columns]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "# vectorizer.fit(X['posts'])\n",
    "# X['posts'] = vectorizer.transform(X['posts'])\n",
    "transformed_posts = np.array([row.toarray() for row in vectorizer.fit_transform(X['posts'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X['category'])\n",
    "X['category'] = vectorizer.transform(X['category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "# vectorizer.fit(X['category'])\n",
    "# X['category'] = vectorizer.transform(X['category'])\n",
    "transformed_data = np.array([row.toarray() for row in vectorizer.fit_transform(X['category'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.shape=(14600,45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data=pd.DataFrame(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=pd.concat([X,transformed_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>category</th>\n",
       "      <th>posts</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>i know, i need to be getting sleep; i know, i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>love studying?can't get enough of those fat b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>Education</td>\n",
       "      <td>Im currently updating my site. And almost doin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>Student</td>\n",
       "      <td>So I was a witness to a pretty nasty accident ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>ok so we skipped multimedia computer lecture...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14595</th>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>ok we got webspace off abp for bgs but of cour...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14596</th>\n",
       "      <td>15</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>dearest diary,  i do not know wad to put for t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14597</th>\n",
       "      <td>16</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Good friends are the greatest treasures of th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14598</th>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>WE BRING THIS SPECIAL ANNOUCEMENT TO YOU LIVE...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14599</th>\n",
       "      <td>25</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>Football Alex 'Knight of the Realm' Ferguson ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14600 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age    category                                              posts  0  \\\n",
       "0      15     Student   i know, i need to be getting sleep; i know, i...  0   \n",
       "1      25      indUnk   love studying?can't get enough of those fat b...  0   \n",
       "2      17   Education  Im currently updating my site. And almost doin...  0   \n",
       "3      24     Student  So I was a witness to a pretty nasty accident ...  0   \n",
       "4      17      indUnk    ok so we skipped multimedia computer lecture...  0   \n",
       "...    ..         ...                                                ... ..   \n",
       "14595  15     Student  ok we got webspace off abp for bgs but of cour...  0   \n",
       "14596  15      indUnk  dearest diary,  i do not know wad to put for t...  0   \n",
       "14597  16      indUnk   Good friends are the greatest treasures of th...  0   \n",
       "14598  23     Student   WE BRING THIS SPECIAL ANNOUCEMENT TO YOU LIVE...  0   \n",
       "14599  25  Accounting   Football Alex 'Knight of the Realm' Ferguson ...  1   \n",
       "\n",
       "       1  2  3  4  5  6  ...  35  36  37  38  39  40  41  42  43  44  \n",
       "0      0  0  0  0  0  0  ...   0   0   0   0   0   1   0   0   0   0  \n",
       "1      0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0   0  \n",
       "2      0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0   0  \n",
       "3      0  0  0  0  0  0  ...   0   0   0   0   0   1   0   0   0   0  \n",
       "4      0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0   0  \n",
       "...   .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
       "14595  0  0  0  0  0  0  ...   0   0   0   0   0   1   0   0   0   0  \n",
       "14596  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0   0  \n",
       "14597  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0   0  \n",
       "14598  0  0  0  0  0  0  ...   0   0   0   0   0   1   0   0   0   0  \n",
       "14599  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0   0  \n",
       "\n",
       "[14600 rows x 48 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= []\n",
    "for hor,gen in zip(df['horoscope'],df['gender']):\n",
    "    labels.append((hor,gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes  ::  14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Aquarius', 'Aries', 'Cancer', 'Capricorn', 'Gemini', 'Leo',\n",
       "       'Libra', 'Pisces', 'Sagittarius', 'Scorpio', 'Taurus', 'Virgo',\n",
       "       'female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(labels)\n",
    "classes=len(mlb.classes_)\n",
    "print(\"classes  :: \", classes)\n",
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = mlb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_dim = trainX.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(20, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(10,  activation='tanh'))\n",
    "# model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(classes, activation='softmax'))\n",
    "# model.add(Activation('softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                714020    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              11264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 14)                14350     \n",
      "=================================================================\n",
      "Total params: 743,940\n",
      "Trainable params: 741,892\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From /home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ebryx/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.5078 - acc: 0.8562 - val_loss: 0.5301 - val_acc: 0.8393\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4573 - acc: 0.8545 - val_loss: 0.4888 - val_acc: 0.8571\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4447 - acc: 0.8625 - val_loss: 0.5128 - val_acc: 0.8536\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3786 - acc: 0.8643 - val_loss: 0.4392 - val_acc: 0.8536\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3753 - acc: 0.8688 - val_loss: 0.4397 - val_acc: 0.8679\n"
     ]
    }
   ],
   "source": [
    "trainX, testX, trainY, testY\n",
    "classifier_nn = model.fit(trainX,trainY,\n",
    "                    epochs=5,\n",
    "                    verbose=True,\n",
    "                    validation_data=(testX, testY),\n",
    "                    batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_1_input to have shape (35700,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-3c3ae4581129>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_1_input to have shape (35700,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "model.predict(testX[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.14142259e-02, 4.55975765e-03, 8.57419595e-02, 2.02653930e-02,\n",
       "        1.70279574e-02, 5.92526468e-03, 2.05481499e-02, 1.84916090e-02,\n",
       "        1.34474393e-02, 1.59376878e-02, 1.16090570e-02, 2.20909212e-02,\n",
       "        7.03751683e-01, 3.91887873e-02],\n",
       "       [1.74757298e-02, 4.07804130e-03, 1.45875901e-01, 2.61220075e-02,\n",
       "        1.86622608e-02, 5.60476817e-03, 2.16874797e-02, 1.78633556e-02,\n",
       "        1.25875454e-02, 2.63237953e-02, 7.83246011e-03, 4.01043221e-02,\n",
       "        5.94223142e-01, 6.15592115e-02],\n",
       "       [3.57897580e-02, 1.03999637e-02, 1.24569289e-01, 3.32498364e-02,\n",
       "        1.22892307e-02, 1.00643709e-02, 3.63702811e-02, 4.06113341e-02,\n",
       "        1.28950682e-02, 2.26842426e-02, 2.85543539e-02, 3.61069217e-02,\n",
       "        3.93447369e-01, 2.02967986e-01],\n",
       "       [3.57734337e-02, 1.03927078e-02, 1.24588579e-01, 3.32387313e-02,\n",
       "        1.22913877e-02, 1.00613032e-02, 3.63560803e-02, 4.05857489e-02,\n",
       "        1.28963655e-02, 2.26806123e-02, 2.85258852e-02, 3.60996723e-02,\n",
       "        3.93791497e-01, 2.02718034e-01],\n",
       "       [2.25615073e-02, 5.06436080e-03, 1.14674486e-01, 2.51986552e-02,\n",
       "        1.46463877e-02, 6.66203815e-03, 2.44518574e-02, 2.19455902e-02,\n",
       "        1.31295053e-02, 1.94369294e-02, 1.20547032e-02, 2.86954045e-02,\n",
       "        6.25555396e-01, 6.59232363e-02],\n",
       "       [4.86470237e-02, 9.26122814e-03, 1.04736395e-01, 4.03735302e-02,\n",
       "        6.42298758e-02, 1.41489580e-02, 3.37319449e-02, 2.72552408e-02,\n",
       "        3.83070447e-02, 3.96946780e-02, 2.84811221e-02, 4.14837189e-02,\n",
       "        3.62125784e-01, 1.47523507e-01],\n",
       "       [3.57565768e-02, 1.03852097e-02, 1.24608442e-01, 3.32272425e-02,\n",
       "        1.22936070e-02, 1.00581096e-02, 3.63413952e-02, 4.05593440e-02,\n",
       "        1.28976991e-02, 2.26768516e-02, 2.84965225e-02, 3.60921882e-02,\n",
       "        3.94146591e-01, 2.02460229e-01],\n",
       "       [3.57897580e-02, 1.03999637e-02, 1.24569289e-01, 3.32498364e-02,\n",
       "        1.22892307e-02, 1.00643709e-02, 3.63702811e-02, 4.06113341e-02,\n",
       "        1.28950682e-02, 2.26842426e-02, 2.85543539e-02, 3.61069217e-02,\n",
       "        3.93447369e-01, 2.02967986e-01],\n",
       "       [3.73620205e-02, 7.61922123e-03, 1.56823948e-01, 4.42551821e-02,\n",
       "        2.70208754e-02, 8.81572440e-03, 3.85817811e-02, 2.25740448e-02,\n",
       "        1.59226600e-02, 4.04785387e-02, 1.52832754e-02, 5.90366051e-02,\n",
       "        3.23420137e-01, 2.02806026e-01],\n",
       "       [3.57600227e-02, 1.03867445e-02, 1.24604374e-01, 3.32296044e-02,\n",
       "        1.22931553e-02, 1.00587597e-02, 3.63444090e-02, 4.05647308e-02,\n",
       "        1.28974319e-02, 2.26776246e-02, 2.85025146e-02, 3.60937268e-02,\n",
       "        3.94074142e-01, 2.02512816e-01],\n",
       "       [1.71760283e-02, 2.64629349e-03, 6.71758098e-05, 7.17785433e-02,\n",
       "        2.89541066e-01, 8.88395905e-02, 3.61343753e-03, 1.48313725e-03,\n",
       "        1.09591298e-01, 1.57258683e-03, 1.00862905e-02, 4.75650141e-03,\n",
       "        3.98841023e-01, 7.10593531e-06],\n",
       "       [2.95655373e-02, 6.64381823e-03, 1.55702442e-01, 3.81162725e-02,\n",
       "        2.22213399e-02, 7.68360170e-03, 3.31099778e-02, 2.36117281e-02,\n",
       "        1.47318225e-02, 3.33758295e-02, 1.42860329e-02, 5.21539077e-02,\n",
       "        4.17963147e-01, 1.50834605e-01],\n",
       "       [3.55336517e-02, 1.02866972e-02, 1.24860540e-01, 3.30748186e-02,\n",
       "        1.23219620e-02, 1.00157484e-02, 3.61469388e-02, 4.02114913e-02,\n",
       "        1.29142990e-02, 2.26260386e-02, 2.81119701e-02, 3.59917246e-02,\n",
       "        3.98808628e-01, 1.99095458e-01],\n",
       "       [3.23100910e-02, 8.91684089e-03, 1.26400158e-01, 3.07353809e-02,\n",
       "        1.25776893e-02, 9.31113400e-03, 3.32498848e-02, 3.54881957e-02,\n",
       "        1.30400294e-02, 2.17026696e-02, 2.31365543e-02, 3.42543907e-02,\n",
       "        4.62273091e-01, 1.56603917e-01],\n",
       "       [2.64238399e-02, 6.78135082e-03, 1.24112062e-01, 2.69927122e-02,\n",
       "        1.25996433e-02, 7.98258092e-03, 2.83630844e-02, 2.86998078e-02,\n",
       "        1.28039392e-02, 1.98179148e-02, 1.66327171e-02, 3.06956358e-02,\n",
       "        5.55382848e-01, 1.02711804e-01],\n",
       "       [3.01158261e-02, 8.05174559e-03, 1.26132578e-01, 2.92673130e-02,\n",
       "        1.25706904e-02, 8.79012700e-03, 3.14331651e-02, 3.26995365e-02,\n",
       "        1.29501270e-02, 2.09661443e-02, 2.03944743e-02, 3.29536870e-02,\n",
       "        4.99514878e-01, 1.34159774e-01],\n",
       "       [3.57645340e-02, 1.03887506e-02, 1.24599040e-01, 3.32326815e-02,\n",
       "        1.22925565e-02, 1.00596137e-02, 3.63483317e-02, 4.05718125e-02,\n",
       "        1.28970677e-02, 2.26786286e-02, 2.85103805e-02, 3.60957012e-02,\n",
       "        3.93979013e-01, 2.02581927e-01],\n",
       "       [2.42779683e-02, 5.97798824e-03, 9.34232026e-02, 2.10089106e-02,\n",
       "        2.24710889e-02, 8.04143120e-03, 3.05403285e-02, 2.92865913e-02,\n",
       "        1.78650152e-02, 1.92836467e-02, 2.35115010e-02, 2.94349175e-02,\n",
       "        5.94915688e-01, 7.99616575e-02],\n",
       "       [3.28814536e-02, 5.15704881e-03, 7.79526383e-02, 2.53978558e-02,\n",
       "        4.43718471e-02, 8.44441727e-03, 2.01765299e-02, 1.80483460e-02,\n",
       "        2.62783039e-02, 2.19018105e-02, 1.65987685e-02, 2.33092103e-02,\n",
       "        6.39237761e-01, 4.02441174e-02],\n",
       "       [4.11195569e-02, 8.81305896e-03, 1.03690229e-01, 4.32515480e-02,\n",
       "        1.76327471e-02, 7.72368070e-03, 4.12647873e-02, 1.83034316e-02,\n",
       "        1.03750564e-02, 4.08126079e-02, 1.74871329e-02, 6.10280931e-02,\n",
       "        8.47506896e-02, 5.03747404e-01]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "for i in trainY:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2 Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_of_posts=[]\n",
    "for j in range(len(data)):\n",
    "    posts=data[j]['posts']\n",
    "    \n",
    "    words=[]\n",
    "    for i in range(len(posts)):\n",
    "        words.append(word_tokenize(posts[i]))\n",
    "    words_of_posts.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stop_words(data[1]['posts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(data)==len(words_of_posts):\n",
    "    for i in range(len(data)):\n",
    "        data[i]['tokenized']=words_of_posts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['tokenized'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X)\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['horoscope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_transform=le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y = np_utils.to_categorical(y_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            word = ps.stem(word)\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "\n",
    "        frequency_matrix[sent[:15]] = freq_table\n",
    "\n",
    "    return frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_matrix=_create_frequency_matrix(data[1]['posts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "\n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_matrix=_create_tf_matrix(freq_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_per_word=_create_documents_per_words(freq_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "\n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_create_idf_matrix(freq_matrix,doc_per_word,total_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
